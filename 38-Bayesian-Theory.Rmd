# Bayesian Theory  

## Introduction of Bayesian

### Frequency school


* A set of random samples, the frequency school believes that the overall parameters are constant, and the samples are obtained randomly;
* The Bayesian school believes that the **overall parameters** are random, and the sample obtained is constant. The Bayesian school does not care much about the correct parameters, but needs to obtain the **posterior** by adding the **acquired data to the prior knowledge**


### Posterior distribution

The posterior distribution summarises our uncertainty over the value of a parameter. If the distribution is narrower, then this indicates that we have greater confidence in our estimates of the parameter’s value. More narrow posterior distributions can be obtained by collecting more data.

* The posterior probability is the probability of the parameters $\theta$ given the evidence $X: p(\theta \mid X)$
* It contrasts with the likelihood function, which is the probability of the evidence given the parameters: $p(X \mid \theta)$

The two are related as follows: Given a prior belief that a probability distribution function is $p(\theta)$ and that the observations $x$ have a likelihood $p(x \mid \theta)$, then the posterior probability is defined as
$$
p(\theta \mid x)=\frac{p(x \mid \theta)}{p(x)} p(\theta)
$$


## 概率分布

在贝叶斯统计中，我们使用概率分布描述不确定性。这样的对象有两种：离散的和连续的概率分布。对于离散情况，可以将分布函数的值解释为概率，因为只有有限数量的离散值定义了这些分布。但是，对于连续概率分布，任何一个值的概率均为零，因为任何此类值的数量都是无限的。而是将连续概率分布的值解释为密度。为了将其转换为概率，我们将密度乘以体积。从数学上讲，这相当于将概率密度函数相对于度量进行积分。


先验是一种概率分布，描述了我们在收集和分析数据之前对假设的信念。在贝叶斯推理中，我们对该假设的分析后信念为后验。 后验概率分布 $\mathrm{P}(\theta | \text{data})$是贝叶斯推理的主要目标。
后验分布总结了我们对参数值的不确定性。如果分布范围更窄，则表明我们对参数值的估计更有信心。通过收集更多数据可以获得更窄的后验分布。后验分布还用于预测实验的未来结果和模型测试。[]




## 充分统计量 Sufficient statistic 

>Definition: Sufficient Statistics    
若给定统计量的值，样本联合密度的条件分布与未知参数无关，则这个统计量为充分统计量。

数理统计的本质是通过样本来做推断，也就是说统计推断是这个学科的主要负责功能。而直观来说，推理需要证据，需要信息，这也就是充分统计量诞生的来源：统计量可不可以尽量少，并且包含样本提供的我们感兴趣的所有信息？你想，如果可以包含一个样本的所有信息，那么这个统计量，直白的来说就可以代替这个样本中的所有数据，从某种意义上来说也是一种降维。这也是为什么充分统计量具有非常大的统计学上的意义。

我们不可能说做加工不丢失信息，但是我们完全可以做到保留所有我感兴趣的信息。书上给了一个非常简单的例子来理解：如果你希望知道样本的均值，那么你需不需要知道一组数据的顺序？ [公式] 和 [公式] 是否是相同的样本？我们一般认为，如果我们只关心均值这个参数，那么这两个样本是没有差别的。

样本本身会存在一个联合密度函数 $F(x)$， 这个函数本质上也就刻画了样本所包含的所有信息（因为在统计学意义上，如果我们对数据拿到了它的不含未知量的分布，那么我们就认为我们已经拿到了所有王牌）。那么假如说我们希望研究一个参数 $\theta$ ，联合密度函数写为 $F_\theta(x)$ ，根据我们的理解，如果给定统计量的值 $T=t$ ，所对应的条件分布 $F_\theta(x \mid T=t)$ 是一个与 $\theta$ 无关的分布，那么你可以看到，这个时候无论 $\theta$ 它怎么蹦跶，只要统计量 $T$ 的值给定了，样本概率密度就不会再变了。反过来说，这个时候只有这个 $T$ 变了，才能对 $\theta$ 产生影响，这也就说明 $\theta$ 的所有信息都被 $T$ 所抓住了，也就是我们说的充分统计量的含义了。









## Conditioning and Bayes' Rule

p(θ|data)[**Bayes**] = p(data|θ)[**Likelihood=L(θ|data)**] p(θ)/p(data)

$$P(H\mid E)={\frac {P(E\mid H)\cdot P(H)}{P(E)}}$$

$\textstyle H$ stands for any hypothesis whose probability may be affected by data (called 
evidence below). Often there are competing hypotheses, and the task is to determine which is
the most probable. 代表任何可能受数据影响的假设（以下称为证据）。通常存在相互竞争的假设，任
务是确定最可能的假设。

$\textstyle P(H)$, the prior probability, is the estimate of the probability of the hypothesis
$\textstyle H$ before the data $\textstyle E$, the current evidence, is observed. $\textstyle E$,
the evidence, corresponds to new data that were not used in computing the prior probability. 
先验概率，是在观察到当前数据E之前，假设概率H的估计.

边缘概率（又称先验概率）：某个事件发生的概率。边缘概率是这样得到的：在联合概率中，把最终结果中那
些不需要的事件通过合并成它们的全概率，而消去它们（对离散随机变量用求和得全概率，对连续随机变量用
积分得全概率），这称为边缘化（marginalization），比如A的边缘概率表示为P(A)，B的边缘概率表示为P(B)。

$\textstyle P(H\mid E)$, the posterior probability, is the probability of $\textstyle H$ given
$\textstyle E$, i.e., after $\textstyle E$ is observed. This is what we want to know: the 
probability of a hypothesis given the observed evidence. 

条件概率（又称后验概率）：事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为P(A|B)，
读作“在B条件下A的概率”,。

$\textstyle P(E\mid H)$ is the probability of observing $\textstyle E$ given $\textstyle H$, and
is called the likelihood. As a function of $\textstyle E$ with $\textstyle H$ fixed, it indicates 
the compatibility of the evidence with the given hypothesis. 




贝叶斯方法的核心就是通过先验知识不断更新后验概率密度来分析参数的可能性分布，如果继续进行实验
，之前的后验概率密度就变成了先验知识，这样最终就会越来越接近参数的真实分布。需要注意的是，一
般来讲如果当前的样本量比先验知识的样本量大很多，那么先验知识就可以忽略不计。另外还有一种先验
知识并不是基于早期试验，而是专家意见













# Likelihood

## 极大似然估计法

似然这个概念首先由Fisher（频率学派祖师爷）提出的，具体就不多说了。对于贝叶斯推断而言，
似然函数可以看作是导工作。


```{r echo =F, error=FALSE, message=FALSE, warning=FALSE, fig.cap="Combining the Repeated Complete-Data Estimates and Variances"}
knitr::include_graphics("./00 Fotos/Likelihood.png")
```



这里需要注意的是两条似然原则：

1. 似然函数包含了所有从实验中获得的包含未知参数的证据。
2. 如果一个似然函数A与另一个似然函数B成比例，那么A和B包含关于未知参数θ的信息相同。


有两种类型的手术，第一种手术选取12个病人，其中有9个成功了（3个失败）；第二种手术则采取
不事先选定人数，而是一直选取病人做手术，直到3个病人失败为止，结果发现总共成功的人数为9
个。那么两种情况的分布分别是：

* 二项分布，似然函数为: ${\displaystyle f(k,n,p)=\Pr(k;n,p)=\Pr(X=k)={\binom {n}{k}}p^{k}(1-p)^{n-k}}$
* 负二项分布，似然函数为: ${\displaystyle f(k,s,p)=\Pr(k;s,p)=\Pr(X=k)={\binom {k+s-1}{k}}p^{k}(1-p)^{s}}$

利用极大似然法，推断出来的参数是一致的，因此他们包含关于未知参数的信息相同。有意思的是，
如果用频率学派的统计推断方法，在相同的零假设下（比如θ=0.5），得出的结论不一样（前者p值为
0.073，后者为0.337）。

当我们假设特定的θ值并改变数据时，结果概率的集合形成概率分布。为什么贝叶斯主义者坚持称p(data|θ) 是似然性，而不是概率呢？”“这是因为在贝叶斯推理中，我们没有使模型的参数保持固定。在贝叶斯分析中，
数据是固定的，参数是变化的。特别是，贝叶斯规则告诉我们如何计算任意θ值的后验概率密度。

极大似然估计是建立在极大似然原理的基础上的一个统计方法，是概率论在统计学中的应用。极大似然估计
提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结
果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计





## 模型的平滑

要求先验概率和反条件概率（模型训练过程），直接统计某样本在训练数据集中的分布即可，这种方法是极大似然估计法。

<!-- 零概率问题和平滑 -->

但是，在实际的模型训练过程中，可能会出现零概率问题（因为先验概率和反条件概率是根据训练样本算的，但训练样本数量不是无限的，所以可能出现有的情况在实际中存在，但在训练样本中没有，导致为0的概率值，影响后面后验概率的计算），即便可以继续增加训练数据量，但对于有些问题来说，数据怎么增多也是不够的。这时我们说模型是不平滑的，我们要使之平滑，一种方法就是将训练（学习）的方法换成贝叶斯估计。


<!-- 贝叶斯估计（又叫贝叶斯学习）和拉普拉斯平滑 -->

```{r echo =F, error=FALSE, message=FALSE, warning=FALSE, fig.cap="Combining the Repeated Complete-Data Estimates and Variances"}
knitr::include_graphics("./00 Fotos/Likelihood_2.png")
```




















# Prior

先验是一种概率分布，描述了我们在收集和分析数据之前对假设的信念。在贝叶斯推理中，我们对该假设的分析后信念为后验。贝叶斯方法对概率的理解是人们对某些事件的一种信任程度，是对事物的不确定性的一种主观判断，与个人因素等有关，故称之为主观概率。 贝叶斯统计中的先验分布反映的就是人们对于待估计参数的主观概率。为了在小样本量下能获得较好的参数估计，就必须利用参数的历史资料或先验知识。

## Non-informativ Priors

通常在贝叶斯分析中，我们需要指定一个先验，但事实在很多前提下，我们是不知道其先验的，这时我们就可以采用无信息先验分布来进行分析计算。

### Problems

```{r,echo = T,message = FALSE, error = FALSE, warning = FALSE, out.width='100%'}
knitr::include_graphics("./00 Fotos/Non-informativ-1.png")
```


### Jeffreys Prior

* Jeffreys在他的书里提出了Jeffreys 先验，
其最主要性质就是不变性（invariant），即先验的形式不随着参数形式变化而变化。
* 较好地解决了无信息先验中的一个矛盾：若对参数θ选用均匀分布，则其函数g(θ)往往不是均匀分布。
* 采用Fisher信息阵的平方根作为θ的无信息先验分布。


### Reference Prior

* Reference prior解决了Jeffreys prior在多元情况下的一些问题
* Reference prior是在极大样本下使得先验分布和后验分布的Kullback–Leibler divergence最大的reference prior。
先验分布和后验分布的Kullback–Leibler 
* divergence可以被理解成这两个分布之间的信息差，而这个信息差显然来自于样本的信息，使得这个信息差最大就说明后验分布主要体现的是样本的信息，reference prior对我们得到的信息几乎没有影响。所以这种先验分布可以叫做noninformative prior。











# Posterior

后验概率分布 $\mathrm{P}(\theta | \text{data})$是贝叶斯推理的主要目标。
后验分布总结了我们对参数值的不确定性。如果分布范围更窄，则表明我们对参数值的估计更有信心。通过收集更多数据可以获得更窄的后验分布。后验分布还用于预测实验的未来结果和模型测试。[The posterior distribution summarises our uncertainty over the value of a parameter. If the distribution is narrower, then this indicates that we have greater confidence in our estimates of the parameter’s value. More narrow posterior distributions can be obtained by collecting more data.]


## 后验概率密度的统计量

```{r,echo = T,message = FALSE, error = FALSE, warning = FALSE}
knitr::include_graphics("./00 Fotos/Posterior-1.png")
```



## Conjugate

共轭（conjugate）是贝叶斯方法中很常见的一个词，结合贝叶斯定理，我们可以将“共轭”理解为后验和先验是同一种分布。

Beispiel 1: 泊松分布-伽马分布模型

```{r,echo = T,message = FALSE, error = FALSE, warning = FALSE, out.width='120%'}
knitr::include_graphics("./00 Fotos/Conjugate_1.png")
```

Beispiel 2: 正态分布-正态分布模型

```{r,echo = T,message = FALSE, error = FALSE, warning = FALSE, out.width='120%'}
knitr::include_graphics("./00 Fotos/Conjugate_2.png")
```








# Bayesian posterior inference


## 参数估计

<!-- https://blog.csdn.net/daunxx/article/details/51725086 -->

在很多的机器学习或数据挖掘的问题中，我们所面对的只有数据，但数据中潜在的概率密度函数是不知道的，其概率密度分布需要我们从数据中估计出来。想要确定数据对应的概率密度分布，就需要确定两个东西：概率密度函数的形式 和 概率密度函数的参数。有时可能知道的是概率密度函数的形式(高斯、瑞利等等)，但是不知道具体的参数，例如均值或者方差；还有的时候可能不知道概率密度的类型，但是知道一些估计的参数，比如均值和方差。

关于上面提到的需要确定的两个东西：概率密度函数的形式和参数，至少在机器学习的教课书上，我所看到的情况都是：给了一堆数据，然后假设其概率密度函数的形式为 高斯分布，或者是混合高斯分布，
那么，剩下的事情就是对高斯分布的参数，μ 和 σ2进行估计。所以，参数估计，便成了极其最重要的问题。
常用的参数估计方法有：极大似然估计、最大后验估计、贝叶斯估计、最大熵估计、混合模型估计。他们之间是有递进关系的，想要理解后一个参数估计方法，最好对前一个参数估计有足够的理解。


在一个基础模型之下我们需要去estimate一些未知的参数（比如在linear regression, 需要去计算W这个向量), 但在贝叶斯模型下我们需要去计算的是W的分布（而不是W的点估计)，用其分布直接计算对y的预测值p(y|x,D)，所以我们需要去需要整合W，也就是说我们把所有可能的W向量都会去考虑.这也为什么贝叶斯模型通常棘手的。所以我们需要用MCMC，不是直接用优化的方法。在贝叶斯模型之下， 随着我们观察到越来越多的数据， 我们会对W向量的分布会有更清晰的推断，这其实就是posterior inference.

我们一般考虑3种预测模式

    Maximum likelihood estimation (ML), (point estimation)
    Maximum a posteriori estimation（MAP)，(point estimation) 
    bayesian Model

### 极大似然估计

Maximum likelihood estimation (ML): 这是最简单的point estimation, 也就是我们需要去计算P(D|W), 从而找到最优化的W. 它的缺点就是数据比较少的时候往往overfit

基本的假设

* 第一：假设M个类别的数据子集的概率密度函数形式一样，只是参数的取值不同；
* 第二：假设类别i中的数据和类别j中的数据是相互独立抽样的，即类别j的参数仅仅根据类别j的数据就可以估计出来，类别i的数据并不能影响类别j的参数估计，反之亦然；
* 第三：每个类别内的样本之间具有统计独立性，即每个类别内的样本之间是独立同分布 (iid) 的。

设x1,x2,...,xN 是从概率密度函数p(x;θ) 中随机抽取的样本，那么就可以得到联合概率密度函数 p(X;θ)，
$$p(X;\theta)\equiv p(x_1,x_2,...,x_N;\theta)=\prod_{k=1}^Np(x_k;\theta)$$
此时，就可以使用最大似然估计(Maximum Likelihood,ML)来估计参数θ了：
$$\hat{\theta}_{ML}=arg\max_{\theta}\prod_{k=1}^Np(x_k;\theta)$$
为了得到最大值，θ^ML^必须满足的必要条件是,似然函数对θ的梯度必须为0，即：
$$\frac{\partial \prod_{k=1}^Np(x_k;\theta)}{\partial\theta}=0$$
一般我们取其对数形式：
$$L(\theta)\equiv ln\prod_{k=1}^Np(x_k;\theta)$$
$$\frac{\partial L(\theta)}{\partial \theta}=\sum_{k=1}^N  \frac{\partial ln p(x_k;\theta)}{\partial \theta}=\sum_{k=1}^N\frac{1}{p(x_k;\theta)} \frac{\partial p(x_k;\theta)}{\partial \theta}=0$$
极大似然估计有两个非常重要的性质：渐进无偏 和渐进一致性，
有了这两个性质，使得极大似然估计的成为了非常简单而且实用的参数估计方法。这里假设$θ_0$是密度函数p(x;θ)
中未知参数的准确值。

极大似然估计是渐进无偏的，即：$$\lim_{N \to \infty}E[\hat{\theta}_{ML}]=\theta_0$$, 也就是说，这里认为估计值 θ^ML^本身是一个随机变量（因为不同的样本集合X会得到不同的 θ^ML^），
那么其均值就是未知参数的真实值，这就是渐进无偏。

极大似然估计是渐进一致的，即：$$\lim_{N \to \infty}prob\{  \lVert \hat{\theta}_{ML}-  \theta_0 \rVert \leqslant \epsilon\} = 1$$,这个公式还可以表示为: $$\lim_{N \to \infty} E \lVert \hat{\theta}_{ML}-  \theta_0 \rVert^2 = 0$$,
对于一个估计器而言，一致性是非常重要的，因为存在满足无偏性，但是不满足一致性的情况，比如，θ^ML^
在 θ-0-周围震荡。如果不满足一致性，那么就会出现很大的方差. 以上两个性质，都是在渐进的前提下（$N \to \infty$）才能讨论的，即只有N足够大时，上面两个性质才能成立
 




### 最大后验估计


在最大似然估计中，将θ看做是未知的参数，说的通俗一点，最大似然估计是θ的函数，其求解过程就是找到使得最大似然函数最大的那个参数θ。 从最大后验估计开始，将参数θ看成一个随机变量，并在已知样本集{x1,x2,...,xN}的条件下，估计参数θ。

这里一定要注意，在最大似然估计中，参数θ是一个定值，只是这个值未知，最大似然函数是θ的函数，这里θ
是没有概率意义的。但是，在最大后验估计中，θ是有概率意义的，θ有自己的分布，而这个分布函数，需要通过已有的样本集合X得到，即最大后验估计需要计算的是 p(θ|X). Maximum a posteriori estimation (MAP). 他是在ML的基础上加了prior, 也就是假定了一些P(θ)的分布根据贝叶斯理论：
$$p(\theta|X)=\frac{p(\theta)p(X|\theta)}{p(X)}$$
这就是参数θ关于已有数据集合X的后验概率，要使得这个后验概率最大，和极大似然估计一样，这里需要对后验概率函数求导。由于分子中的p(X)相对于θ是独立的，随意可以直接忽略掉p(X)。
$$\hat{\theta}_{MAP}=arg\max_{\theta}p(\theta|X)=arg\max_{\theta}p(\theta)p(X|\theta)$$
为了得到参数θ，和ML一样，需要对p(θ|X)求梯度，并使其等于0：
$$\frac{p(\theta|X)}{\partial\theta}=\frac{p(\theta)p(X|\theta）}{\partial\theta}=0$$
这里p(X|θ)和极大似然估计中的似然函数p(X;θ)
是一样的，只是记法不一样。MAP和ML的区别是：MAP是在ML的基础上加上了p(θ)

在MAP中，p(θ)称为θ的先验，假设其服从均匀分布，即对于所有θ取值，p(θ)都是同一个常量，则MAP和ML会得到相同的结果。当然了，如果p(θ)的方差非常的小，也就是说，p(θ)是近似均匀分布的话，MAP和ML的结果自然也会非常的相似。


 



### 贝叶斯估计

#### Introduction

MAP的一些limitation 贝叶斯可以帮我们解决. 贝叶斯的特点就是考虑整个X的分布，所以自然而然也就是防止overfitting. 
为了防止标号混淆，这里定义已有的样本集合为D，而不是之前的X。
样本集合D中的样本都是从一个 固定但是未知的概率密度函数p(x)中独立抽取出来的，要求根据这些样本估计x的概率分布，记为p(x|D)，并且使得p(x|D)尽量的接近p(x)，这就是贝叶斯估计的核心问题。在这里我们是计算x的分布，而不是x的一个最优化的值！（不同于MAP)。 

虽然p(x)是未知的，但是前面提到过，一个密度分布的两个要素为：形式和参数，
我们可以假设p(x)的形式已知，但是参数θ的取值未知。这里就有了贝叶斯估计的第一个重要元素**p(x|θ)**, 
这是一个条件概率密度函数，准确的说，是一个类条件概率密度函数.
p(x|θ)的形式是已知的，只是参数θ的取值未知。由于这里的x可以看成一个测试样本，
所以这个条件密度函数，从本质上讲，是θ在点 x 处的似然估计。

由于参数θ的取值未知，且，我们将θ看成一个随机变量，那么，在观察到具体的训练样本之前，
关于θ的全部知识，可以用一个先验概率密度函数p(θ)来表示，对于训练样本的观察，
使得我们能够把这个先验概率密度转化成为后验概率密度函数p(θ|D)，
根据后验概率密度相关的论述知道，我们希望p(θ|D)在θ的真实值附近有非常显著的尖峰。
这里的这个后验概率密度**p(θ|D)**，就是贝叶斯估计的第二个主要元素。

现在，将贝叶斯估计核心问题p(x|D)，和贝叶斯估计的两个重要元素：p(x|θ)、p(θ|D)联系起来
$$p(x|D)=\int p(x,\theta|D) d\theta=\int p(x|\theta,D)p(\theta|D)d\theta$$
* x 是测试样本
* D 是训练集，x和D的选取是独立进行的, 因此，p(x|θ,D)可以写成p(x|θ),
所以，贝叶斯估计的核心问题就是下面这个公式：

$$p(x|D)=\int p(x|\theta)p(\theta|D)d\theta$$
* p(x|D) 根据这些样D本估计x的概率分布
* p(x|θ) 假设p(x)的形式已知，但是参数θ的取值未知, p(x|θ)的形式是已知的，只是参数θ的取值未知, 这里p(x|θ)
是θ关于测试样本x这一个点的似然估计
* p(θ|D) 在观察到具体的训练样本之前，关于θ的全部知识，可以用一个先验概率密度函数p(θ)来表示，对于训练样本的观察，使得我们能够把这个先验概率密度转化成为后验概率密度函数p(θ|D) (p(θ|D)是θ在已有样本集合上的后验概率)
$$p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)}=\frac{p(D|\theta)p(\theta)}{\int p(D|\theta)p(\theta)d\theta}$$
$$p(D|\theta)=\prod_{k=1}^N p(x_k|\theta)$$







#### full-Bayesian

full-Bayesian与最大似然估计，最大后验估计（MAP）不同之处在于它得到的是测试数据在整个空间上的一个概率分布，而不单纯是一个点估计。它的精髓就在于这个加权积分：考虑到了参数的所有情况，并且加以不同的权重（后验分布的值），自然就避免了过拟合。此外，很多情况下比起单纯的点估计，我们更需要一个分布来获得更多的信息（点估计只告诉了我们最有可能的情况，而分布包含了整个空间里的情况）。

```
Step 1: 用训练数据得到似然函数likelihood，再加上一个先验分布prior，得到一个后验分布posterior.
Step 2: 对于一个新的测试数据x，用之前得到的posterior作为权重在整个参数空间里计算一个加权积分，得到一个预测分布。
```
在实际中，除了少数情况（比如先验和似然函数都是高斯分布），那个后验分布的形式一般都很复杂，第二步里的积分是积不出来的。这时候就要采取一些近似方法，近似方法又分为两大类：

* 简化复杂的后验分布，然后就能算出积分的解析形式了。具体方法有变分推断，Laplace近似等。这类方法的特点是人算起来困难，机器跑起来快。
* 用采样的方法搞定后验分布。具体方法有Gibbs采样，HMC采样等。这类方法反过来了，人算起来简单，但是机器跑起来慢。采样方法还有一个好处，就是精度算得比谁都高
 

#### 贝叶斯估计的增量学习

为了明确的表示样本集合D^n^中有n个样本，这里采用记号：Dn={x1,x2,...,xn}。根据公式
$$p(D|\theta)=\prod_{k=1}^N p(x_k|\theta)$$
在n>1的情况下有：
$$p(D^n|\theta)=p(x_n|\theta)p(D^{n-1}|\theta)$$
$$p(\theta|D^n)=\frac{p(x_n|\theta)p(D^{n-1}|\theta)p(\theta)}{\int p(x_n|\theta)p(D^{n-1}|\theta)p(\theta)d\theta}=\frac{p(x_n|\theta)p(\theta |D^{n-1})}{\int p(x_n|\theta)p(\theta |D^{n-1})d\theta}$$
当没有观测样本时，定义$p(\theta|D^0)=p(\theta)$，为参数θ
的初始估计。然后让样本集合依次进入上述公式，就可以得到一系列的概率密度函数：$p(\theta|D^0),p(\theta|D^1),p(\theta|D^2),...$,这一过程称为参数估计贝叶斯递归法，也叫贝叶斯估计的增量学习。这是一个在线学习算法，它和随机梯度下降法有很多相似之处。








# 贝叶斯线性回归

如果要将极大似然估计应用到线性回归模型中，模型的复杂度会被两个因素所控制：基函数的数目和样本的数目。尽管为对数极大似然估计加上一个正则项（或者是参数的先验分布），在一定程度上可以限制模型的复杂度，防止过拟合，但基函数的选择对模型的性能仍然起着决定性的作用。

----由于极大似然估计总是会使得模型过于的复杂以至于产生过拟合的现象，所以单纯的适用极大似然估计并不是特别的有效。

----交叉验证是一种有效的限制模型复杂度，防止过拟合的方法，但是交叉验证需要将数据分为训练集合测试集，对数据样本的浪费也是非常的严重的。

贝叶斯线性回归不仅可以解决极大似然估计中存在的过拟合的问题，而且，它对数据样本的利用率是100%，仅仅使用训练样本就可以有效而准确的确定模型的复杂度。线性回归模型是一组输入变量x的基函数的线性组合，在数学上其形式如下： 
$$y(x,w)=w_{0}+\sum_{j=1}^{M}\omega_{j}\phi_{j}(x)$$
这里$ϕ_j(x)$就是基函数(输入向量x的基函数f(x)的线性组合)，总共的基函数的数目为M个，如果定义$ϕ_0(x)=1的$话，那个上面的式子就可以简单的表示为： 
$$y(x,w)=\sum_{j=0}^{M}\omega_{j}\phi_{j}(x)=w^T\phi(x)$$
$$w=(w_{0},w_{1},w_{2},...,w_{M})$$
$$\phi=(\phi_{0},\phi_{1},\phi_{2},...,\phi_{M})$$
则线性模型的概率表示如下
$$p(t|x,w,\beta)=N(t|y(x,w),\beta^{-1}I)$$
假设参数w满足高斯分布，这是一个先验分布：
$$p(w)=N(w|0,\alpha^{-1}I)$$
一般来说，我们称p(w)为共轭先验(conjugate prior)。这里t是x对应的目标输出.
$\beta^{-1},\alpha^{-1}$别对应于样本集合和w的高斯分布的方差，w是参数，
那么，线性模型的对数后验概率函数：
$$ln p(\theta|D)=ln p(w|T)=-\frac{\beta}{2}\sum_{n=1}^N\{y(x_{n},w)-t_{n}\}^2+\frac{\alpha}{2}w^Tw+const$$
这里T是数据样本的目标值向量，T={t1,t2,...,tn}，const是和参数w无关的量。




## 贝叶斯线性回归的学习过程

```{r,echo = T,message = FALSE, error = FALSE, warning = FALSE, out.width = '120%'}
knitr::include_graphics("./00 Fotos/bayesian_learn.jpg")
```










# Bootstrap

Bootstrap 是一种用小样本来估计大样本的统计方法，斯坦福统计系主任的Bradley Efron在70年代提出。 中心思想是通过从样本中重抽样（resample），构建某个估计的置信区间。抽象的说，通过样本得到的估
计并没有榨干样本中的信息，bootstrap利用重抽样，把剩余价值发挥在了构建置信区间上。

* 首先，Bootstrap通过重抽样，可以避免了Cross-Validation造成的样本减少问题
* 其次，Bootstrap也可以用于创造数据的随机性。比如，我们所熟知的随机森林算法第一步就是从原始训
练数据集中，应用bootstrap方法有放回地随机抽取k个新的自助样本集，并由此构建k棵分类回归树。



## Bootstrap VS Monte Carlo

* Bootstrap是对现有的数据，不断再随机取小的样本，对每个小样处理数据,得到estimator.从而来了解
estimator 的variation or distribution. 
* Monte Carlo 是用一个algorithm,依次输出数组，然后对这些数组处理，得到想要的结果。数组之间的
关系由algorithm来决定。Monte Carlo 的概念更广泛。Bootstrap 其实是一种Monte Carlo.
{从某种意义上，Mente Carlo是一种计算积分的方法，期望，方差等等都是在概率空间的积分，先采样，
再加和。一般用在两个地方，一是在closed form拿不到的情况下来做的，二是空间维度非常高，因为
Mente Carlo的收敛阶依赖于采样点的个数（半阶收敛）而和空间维数没有关系，在特别高维的问题中计算
积分，Mente Carlo甚至成为了唯一可行的方法。}
 











# 朴素贝叶斯（Naive Bayesian）

在机器学习二分类问题中，A是标签值，B是特征值，我们用贝叶斯算法的预测过程，就是用贝叶斯公式求解上述条件概率的过程。通过我们所有的训练样本或观测数据（训练过程就是求得先验概率和反条件概率的过程），就可以算出P(A)和P(B|A)、P(B|A逆)，从而求得这个条件概率。但是，在这里我们的A和B都只取一个值（发生和不发生），当A取多个值时，就是多分类问题，暂不考虑；当B取多个值时，会遇到一个问题，就是P(B|A)的计算。


**举例：经典的垃圾邮件过滤问题：**

一封垃圾邮件X，由d个单词组成，分别为x1,x2,...,xd。（d个特征/属性）y=1表示是垃圾邮件，y=0表示不是，那么我们的预测过程就是求
$$\mathrm{P}(Y=1 \mid X) = \frac{\mathrm{P}(Y=1)\mathrm{P}(X \mid Y=1)}{\mathrm{P}(X)}$$
$$\mathrm{P}(Y=0 \mid X) = \frac{\mathrm{P}(Y=0)\mathrm{P}(X \mid Y=0)}{\mathrm{P}(X)}$$
谁大，y就取谁，这样完成垃圾邮件的识别。（两者可以用相除方式比较，还可以去掉P(X)).现在需要计算P(y=1)和P(X|y=1)、P(y=0)和P(X|y=0)的值。

P(y=1)和P(y=0)直接统计某样本在训练数据集中的分布即可。（即极大似然估计）而P(X|y=1)则没那么简单了，直观理解，它表示一封邮件是垃圾邮件的条件下，它会包含X中的那些词（特征）的概率是多少。即：P(X|y=1)=P(x1,x2,...,xd|y=1)。也就是说，这里的待预测样本点X包含的是一系列词/特征（词的是否存在，可以用特征值是1还是0表示），代表着一系列特征值的取值。

要求这个概率，需要回到训练集中计算，计算垃圾邮件中包含这些词的邮件数占总垃圾邮件数的比率。很明显这个概率是非常低的，因为那么多词，其各种组合数是指数级增长的，即便你有再多的训练样本也是不够的。也就是说按这样组合求概率就会造成样本稀疏性。很明显，由于不可能有那么大规模的训练集（或者说获取成本很高），解决的办法只能是在某种假设下进行近似计算，对这个概率表达式稍作修改。
$$\text{假设：各个词（特征）之间具备条件独立性（条件就是特征，即特征的条件独立假设）}$$
X和Y之间有条件独立性，则P(X,Y|Z)=P(X|Z)P(Y|Z)，符号表示X⊥Y|Z, 这时：P(x1,x2,...,xd|y=1)=P(x1|y=1)*P(x2|y=1)*P(x3|y=1)…… 通过额外加入假设以减小问题复杂性，我们用比较简单的方式解决了这个问题，这就是朴素贝叶斯（Naive Bayesian）。


```
优点：

1、算法比较简单，容易解释。
2、训练速度快，即便数据规模很大（训练和预测过程仅仅是特征概率的数学运算，而条件独立性假设又将复杂度大大降低）
3、在数据量相对较小，特征数相对较大时表现较好（比如文本数据）。（受无关特征的影响较小）
4、不容易受噪声点和遗漏点影响。（因为在计算概率时，单个点被平均了）
5、支持增量式运算，即可以实时的对新增的样本进行训练。

缺点：

1、因为强加的特征的条件独立假设，所以平均预测准确度不是很高
——并不是说非得条件独立才能用NB，而是说为了解决问题而做的妥协，研究表明NB在即便特征不独立时也表现得还可以。

2、处理文本时会忽略次序、组合、二义性等问题
——搜索芝加哥公牛，出来的是芝加哥这个城市和公牛这种动物。所以有词序、有组合的文本不太适合用此算法。朴素贝叶斯并不理解文本，而只是基于词的频率作为分类的依据。
```







# Markov Model

## 马尔可夫链

因为朴素贝叶斯的条件独立性假设，所以它在处理文本时，不考虑上下文相关的特性。但相同的一句话，不同的词序可能意义完全不同。所以NB只能进行文本分类，但对于更高级的自然语言处理（Neuro-linguistic programming）等问题则无能为力。但要考虑词序问题，条件概率的计算将更加复杂。所以引入马尔可夫假设进行简化：
$$\text{任意一个词（特征）出现的概率（分布）只与其前面的一个词的相关。}$$
一阶假设，如果假设与前面的两个词相关就是二阶假设，但因为使用更高阶模型的时间复杂度几乎呈指数增长。而且考虑其性能，三以上时性能的提升就不是很显著了。符合马尔可夫假设的随机过程叫做马尔可夫过程或马尔可夫链。


## 隐马尔可夫模型

隐马尔可夫模型（Hidden Markov Model，HMM）
是马尔可夫链的一个扩展，也是结构最简单的动态贝叶斯网络。主要用于时序数据建模，在NLP和语音识别等领域有广泛应用。











# 半朴素贝叶斯

将特征的条件独立性假设稍微放松，适当考虑一部分特征间的依赖性，比如独依赖设计（One-Dependent Estimator，ODE），即假设每个特征最多仅依赖一个其他特征（父特征）。又包括SPODE（所有特征共有一个超父）、AODE等。









# 贝叶斯网络

借助有向无环图（Directed acyclic graph，DAG）刻画特征（属性）之间的关系，用条件概率表（Conditional Probability Table，CPT）描述特征间的联合概率分布。

贝叶斯网络能表示任意特征之间的依赖性。

贝叶斯网络是马尔可夫链的推广，是一种概率图模型。